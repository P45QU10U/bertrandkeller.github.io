<!DOCTYPE html> <html lang="fr"> <head itemscope itemtype="http://schema.org/WebSite"> <meta charset="utf-8"> <link href="https://gmpg.org/xfn/11" rel="profile"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <title>Les bases du test A/B, par Paras Chopra | bertrandkeller</title> <meta property="og:title" content="Les bases du test A/B, par Paras Chopra"/> <meta property="og:locale" content="fr"/> <meta name="description" content="Paras Chopra nous donne quelques règles élémentaires du test A/B. Le principe de ce genre de test est simple : plutôt que de tester les performances de vos interfaces avant leur sortie avec un panel limité d&#39;utilisateurs ; préférer faire le test en production, avec plus de visiteurs, en redirigeant une partie des utilisateurs sur une proposition A et l&#39;autre partie sur une proposition B. Le test A/B permet de sonder un nombre plus important de personnes, donc d&#39;avoir un retour plus fiable sur la performance de certaines interfaces. Ce type de test propose l&#39;avantage d&#39;avoir un retour de la performance dans des conditions de production, sans perturber le fonctionnement global du site, puisque seule une petite partie des visiteurs est soumise aux tests. Fixer les objectifs principaux Pour mesurer le succès d&#39;une batterie de tests, il est important de définir au préalable les objectifs à atteindre, par exemple : Augmenter le trafic Augmenter l&#39;engagement utilisateur Améliorer la rentabilité de la publicité ... Quel que soit le test à mettre en place, insister pour appliquer qu&#39;un seul type de test à la fois. C&#39;est la seule façon de mesurer et de garantir les résultats : quand je mets le bouton à droite, la conversion utilisateurs augmente de 22%. Le A/B testing n&#39;est pas facile, non seulement, il faut définir les objectifs (un seul à la fois), mais aussi ne modifier qu&#39;un seul élément à la fois. Cette manière de procéder est la seule permettant de bien valider si une modification est bénéfique et surtout d&#39;en déterminer la raison véritable. Oui, mais quoi tester ? Une page bourrée de liens devant vous, des choix divers pour chacun des visiteurs du site, par quoi faut-il commencer ? Plusieurs pistes pour décider de la fonctionnalité à passer au banc d&#39;essai. Séance de tests utilisateurs pour faire un bilan du site Solliciter ses meilleurs amis et ses collègues Fouiller les statistiques (analytics) du site User de la carte de chaleur (heatmap) pour voir où les usagers cliquent Construire son test On a l&#39;objectif, on a les recommandations sur les améliorations à apporter ; maintenant, il faut définir le test. Pour cela déterminer les variations possibles de l&#39;élément à tester. Attention car trop de variations augmente les temps de tests et trop peu de variations peut donner des résultats peu significatifs. Il faut trouver le juste milieu. Le test dépend de chaque site. Il est possible de s&#39;inspirer de la concurrence pour commencer. L&#39;exercice sera un savant mélange entre pertinence et créativité. Conclusion Le test A/B est très séduisant dans la forme, il peut permettre d&#39;avoir des certitudes sur la mise en place d&#39;une évolution sur le site de production : ça marche moins bien ou ça marche mieux. Seulement, pour qu&#39;un test soit significatif, il faut que le protocole soit défini de manière rigoureuse par rapport à un objectif précis. D&#39;une certaine manière, il faut que le gain par rapport au temps passé soit positif. Lire Gathering variables for A/B split testing."/> <meta property="og:description" content="Paras Chopra nous donne quelques règles élémentaires du test A/B. Le principe de ce genre de test est simple : plutôt que de tester les performances de vos interfaces avant leur sortie avec un panel limité d&#39;utilisateurs ; préférer faire le test en production, avec plus de visiteurs, en redirigeant une partie des utilisateurs sur une proposition A et l&#39;autre partie sur une proposition B. Le test A/B permet de sonder un nombre plus important de personnes, donc d&#39;avoir un retour plus fiable sur la performance de certaines interfaces. Ce type de test propose l&#39;avantage d&#39;avoir un retour de la performance dans des conditions de production, sans perturber le fonctionnement global du site, puisque seule une petite partie des visiteurs est soumise aux tests. Fixer les objectifs principaux Pour mesurer le succès d&#39;une batterie de tests, il est important de définir au préalable les objectifs à atteindre, par exemple : Augmenter le trafic Augmenter l&#39;engagement utilisateur Améliorer la rentabilité de la publicité ... Quel que soit le test à mettre en place, insister pour appliquer qu&#39;un seul type de test à la fois. C&#39;est la seule façon de mesurer et de garantir les résultats : quand je mets le bouton à droite, la conversion utilisateurs augmente de 22%. Le A/B testing n&#39;est pas facile, non seulement, il faut définir les objectifs (un seul à la fois), mais aussi ne modifier qu&#39;un seul élément à la fois. Cette manière de procéder est la seule permettant de bien valider si une modification est bénéfique et surtout d&#39;en déterminer la raison véritable. Oui, mais quoi tester ? Une page bourrée de liens devant vous, des choix divers pour chacun des visiteurs du site, par quoi faut-il commencer ? Plusieurs pistes pour décider de la fonctionnalité à passer au banc d&#39;essai. Séance de tests utilisateurs pour faire un bilan du site Solliciter ses meilleurs amis et ses collègues Fouiller les statistiques (analytics) du site User de la carte de chaleur (heatmap) pour voir où les usagers cliquent Construire son test On a l&#39;objectif, on a les recommandations sur les améliorations à apporter ; maintenant, il faut définir le test. Pour cela déterminer les variations possibles de l&#39;élément à tester. Attention car trop de variations augmente les temps de tests et trop peu de variations peut donner des résultats peu significatifs. Il faut trouver le juste milieu. Le test dépend de chaque site. Il est possible de s&#39;inspirer de la concurrence pour commencer. L&#39;exercice sera un savant mélange entre pertinence et créativité. Conclusion Le test A/B est très séduisant dans la forme, il peut permettre d&#39;avoir des certitudes sur la mise en place d&#39;une évolution sur le site de production : ça marche moins bien ou ça marche mieux. Seulement, pour qu&#39;un test soit significatif, il faut que le protocole soit défini de manière rigoureuse par rapport à un objectif précis. D&#39;une certaine manière, il faut que le gain par rapport au temps passé soit positif. Lire Gathering variables for A/B split testing."/> <link rel="canonical" href="https://bertrandkeller.info/2010/04/16/les-bases-du-test-ab-par-paras-chopra/"/> <meta property="og:url" content="https://bertrandkeller.info/2010/04/16/les-bases-du-test-ab-par-paras-chopra/"/> <meta property="og:site_name" content="bertrandkeller"/> <meta property="og:type" content="article"/> <meta property="article:published_time" content="2010-04-16T15:27:09+02:00"/> <meta name="twitter:card" content="summary"/> <meta name="twitter:site" content="@bertrandkeller"/> <script type="application/ld+json">
{"name":null,"description":"Paras Chopra nous donne quelques règles élémentaires du test A/B. Le principe de ce genre de test est simple : plutôt que de tester les performances de vos interfaces avant leur sortie avec un panel limité d&#39;utilisateurs ; préférer faire le test en production, avec plus de visiteurs, en redirigeant une partie des utilisateurs sur une proposition A et l&#39;autre partie sur une proposition B. Le test A/B permet de sonder un nombre plus important de personnes, donc d&#39;avoir un retour plus fiable sur la performance de certaines interfaces. Ce type de test propose l&#39;avantage d&#39;avoir un retour de la performance dans des conditions de production, sans perturber le fonctionnement global du site, puisque seule une petite partie des visiteurs est soumise aux tests. Fixer les objectifs principaux Pour mesurer le succès d&#39;une batterie de tests, il est important de définir au préalable les objectifs à atteindre, par exemple : Augmenter le trafic Augmenter l&#39;engagement utilisateur Améliorer la rentabilité de la publicité ... Quel que soit le test à mettre en place, insister pour appliquer qu&#39;un seul type de test à la fois. C&#39;est la seule façon de mesurer et de garantir les résultats : quand je mets le bouton à droite, la conversion utilisateurs augmente de 22%. Le A/B testing n&#39;est pas facile, non seulement, il faut définir les objectifs (un seul à la fois), mais aussi ne modifier qu&#39;un seul élément à la fois. Cette manière de procéder est la seule permettant de bien valider si une modification est bénéfique et surtout d&#39;en déterminer la raison véritable. Oui, mais quoi tester ? Une page bourrée de liens devant vous, des choix divers pour chacun des visiteurs du site, par quoi faut-il commencer ? Plusieurs pistes pour décider de la fonctionnalité à passer au banc d&#39;essai. Séance de tests utilisateurs pour faire un bilan du site Solliciter ses meilleurs amis et ses collègues Fouiller les statistiques (analytics) du site User de la carte de chaleur (heatmap) pour voir où les usagers cliquent Construire son test On a l&#39;objectif, on a les recommandations sur les améliorations à apporter ; maintenant, il faut définir le test. Pour cela déterminer les variations possibles de l&#39;élément à tester. Attention car trop de variations augmente les temps de tests et trop peu de variations peut donner des résultats peu significatifs. Il faut trouver le juste milieu. Le test dépend de chaque site. Il est possible de s&#39;inspirer de la concurrence pour commencer. L&#39;exercice sera un savant mélange entre pertinence et créativité. Conclusion Le test A/B est très séduisant dans la forme, il peut permettre d&#39;avoir des certitudes sur la mise en place d&#39;une évolution sur le site de production : ça marche moins bien ou ça marche mieux. Seulement, pour qu&#39;un test soit significatif, il faut que le protocole soit défini de manière rigoureuse par rapport à un objectif précis. D&#39;une certaine manière, il faut que le gain par rapport au temps passé soit positif. Lire Gathering variables for A/B split testing.","author":null,"@type":"BlogPosting","url":"https://bertrandkeller.info/2010/04/16/les-bases-du-test-ab-par-paras-chopra/","image":null,"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://bertrandkeller.info/assets/bertrandkeller.png"}},"headline":"Les bases du test A/B, par Paras Chopra","dateModified":"2010-04-16T15:27:09+02:00","datePublished":"2010-04-16T15:27:09+02:00","sameAs":null,"mainEntityOfPage":{"@type":"WebPage","@id":"https://bertrandkeller.info/2010/04/16/les-bases-du-test-ab-par-paras-chopra/"},"@context":"http://schema.org"}</script> <meta property="og:type" content="post"/> <meta name="subject" content="Histoire de gestion de contenu, générateur de site statique et autres"> <meta name="generator" content="jekyll v3.6.2"> <meta itemprop="name" content="Les bases du test A/B, par Paras Chopra | bertrandkeller"> <meta itemprop="description" content="Histoire de gestion de contenu, générateur de site statique et autres"> <meta itemprop="image" content="/assets/bertrandkeller.png"> <meta name="robots" content=""> <link rel="preload" href="/assets/css/font.css" as="stylesheet"> <link href="/assets/css/main.css" rel="stylesheet"> <script data-no-instant>
    !function(){"use strict";function e(e,t,n){e.addEventListener?e.addEventListener(t,n,!1):e.attachEvent&&e.attachEvent("on"+t,n)}function t(e){return window.localStorage&&localStorage.font_css_cache&&localStorage.font_css_cache_file===e}function n(){if(window.localStorage&&window.XMLHttpRequest)if(t(o))c(localStorage.font_css_cache);else{var n=new XMLHttpRequest;n.open("GET",o,!0),e(n,"load",function(){4===n.readyState&&(c(n.responseText),localStorage.font_css_cache=n.responseText,localStorage.font_css_cache_file=o)}),n.send()}else{var a=document.createElement("link");a.href=o,a.rel="stylesheet",a.type="text/css",document.getElementsByTagName("head")[0].appendChild(a),document.cookie="font_css_cache";}}function c(e){var t=document.createElement("style");t.innerHTML=e,document.getElementsByTagName("head")[0].appendChild(t),document.getElementsByTagName("html")[0].className+=' font-loaded'}var o="/assets/css/font.css";window.localStorage&&localStorage.font_css_cache||document.cookie.indexOf("font_css_cache")>-1?n():e(window,"load",n)}();

  </script> <link href="/humans.txt" rel="author" type="text/plain"/> <link href="https://bertrandkeller.info/feed/" rel="alternate" type="application/rss+xml" title="bertrandkeller RSS Feed"/> <meta name="google-site-verification" content="TLPgjqS26dGLPiEz9QUF3u5uaTQnvQRAc3HoaRvC_S8"/> <link rel="preload" href="/favicon.ico" as="image"> <link rel="apple-touch-icon" sizes="180x180" href="/assets/favicons/apple-touch-icon.png"> <link rel="manifest" href="/manifest.json"> <link rel="mask-icon" href="/assets/favicons//safari-pinned-tab.svg" color="#5bbad5"> <meta name="theme-color" content="#000000"> <meta name="msapplication-config" content="/browserconfig.xml"> </head> <body class="page" itemscope itemtype="http://schema.org/WebPage"> <div class="skip-links"> <a href="#main">Contenu principal</a> </div> <header class="site-header" role="banner"> <div class="site-header-top site-header-top__align wrapper"> <p class="site-logo"> <a class="site-title" href="/">bertrandkeller</a> </p> <nav class="nav-main nav-main__scroll" role="navigation"> <ul> <li><a class="page-link" href="/archives/">Archives</a></li> <li><a class="page-link" href="/conseil-prestation-formation/">Prestations</a></li> <li><a class="page-link" href="/site-internet-conference/">Portfolio</a></li> </ul> </nav> </div> </header> <main id="main" role="main"> <div class="wrapper"> <article class="post"> <h1 class="post-title">Les bases du test A/B, par Paras Chopra</h1> <p class="post-meta">16/04/2010</p> <p>Paras Chopra nous donne quelques règles élémentaires du test A/B. Le principe de ce genre de test est simple : plutôt que de tester les performances de vos interfaces avant leur sortie avec un panel limité d'utilisateurs ; préférer faire le test en production, avec plus de visiteurs, en redirigeant une partie des utilisateurs sur une proposition A et l'autre partie sur une proposition B.</p> <p>Le test A/B permet de sonder un nombre plus important de personnes, donc d'avoir un retour plus fiable sur la performance de certaines interfaces. Ce type de test propose l'avantage d'avoir un retour de la performance dans des conditions de production, sans perturber le fonctionnement global du site, puisque seule une petite partie des visiteurs est soumise aux tests.</p> <h3>Fixer les objectifs principaux</h3> <p>Pour mesurer le succès d'une batterie de tests, il est important de définir au préalable les objectifs à atteindre, par exemple :</p> <ul> <li>Augmenter le trafic</li> <li>Augmenter l'engagement utilisateur</li> <li>Améliorer la rentabilité de la publicité</li> <li>...</li> </ul> <p>Quel que soit le test à mettre en place, insister pour appliquer qu'un seul type de test à la fois. C'est la seule façon de mesurer et de garantir les résultats : quand je mets le bouton à droite, la conversion utilisateurs augmente de 22%.</p> <p>Le A/B testing n'est pas facile, non seulement, il faut définir les objectifs (un seul à la fois), mais aussi ne modifier qu'un seul élément à la fois. Cette manière de procéder est la seule permettant de bien valider si une modification est bénéfique et surtout d'en déterminer la raison véritable.</p> <h3>Oui, mais quoi tester ?</h3> <p>Une page bourrée de liens devant vous, des choix divers pour chacun des visiteurs du site, par quoi faut-il commencer ? Plusieurs pistes pour décider de la fonctionnalité à passer au banc d'essai.</p> <ul> <li>Séance de tests utilisateurs pour faire un bilan du site</li> <li>Solliciter ses meilleurs amis et ses collègues</li> <li>Fouiller les statistiques (analytics) du site</li> <li>User de la carte de chaleur (heatmap) pour voir où les usagers cliquent</li> </ul> <h3>Construire son test</h3> <p>On a l'objectif, on a les recommandations sur les améliorations à apporter ; maintenant, il faut définir le test. Pour cela déterminer les variations possibles de l'élément à tester.</p> <p>Attention car trop de variations augmente les temps de tests et trop peu de variations peut donner des résultats peu significatifs. Il faut trouver le juste milieu.</p> <p>Le test dépend de chaque site. Il est possible de s'inspirer de la concurrence pour commencer. L'exercice sera un savant mélange entre pertinence et créativité.</p> <h3>Conclusion</h3> <p>Le test A/B est très séduisant dans la forme, il peut permettre d'avoir des certitudes sur la mise en place d'une évolution sur le site de production : ça marche moins bien ou ça marche mieux. Seulement, pour qu'un test soit significatif, il faut que le protocole soit défini de manière rigoureuse par rapport à un objectif précis. D'une certaine manière, il faut que le gain par rapport au temps passé soit positif.</p> <p>Lire <a href="http://www.uxbooth.com/blog/gathering-variables-for-ab-split-testing/" title="Gathering variables for A/B split testing - Paras Chopra">Gathering variables for A/B split testing</a>.</p> </article> <nav class="pagination--prevnext" role="navigation"> <div class="pagination--prev"> <a class="pagination--item" href="/2010/04/15/lipad-ne-va-pas-sauver-la-presse/"> L'iPad ne va pas sauver la presse </a> </div> <div class="pagination--next"> <a class="pagination--item" href="/2010/04/19/de-la-calculabilite-de-nos-pensees/"> De la calculabilité de nos pensées </a> </div> </nav> </div> </main> <script data-no-instant>
		if (navigator.serviceWorker) {
			navigator.serviceWorker.register('/sw.js', {
					scope: '/'
			});
			window.addEventListener('load', function() {
					if (navigator.serviceWorker.controller) {
							navigator.serviceWorker.controller.postMessage({'command': 'trimCaches'});
					}
			});
		}
</script> </body> </html>