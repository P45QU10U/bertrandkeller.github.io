---
layout: post
title: Les bases du test A/B, par Paras Chopra
date: 2010-04-16 15:27:09.000000000 +02:00
type: post
published: true
status: publish
categories:
- CSS + HTML
tags:
- ergonomie
- qualité
meta:
  _edit_last: '2'
author:
  login: bertrand
  email: bertrand.keller@gmail.com
  display_name: bertrand keller
  first_name: bertrand
  last_name: keller
---
<p>Paras Chopra nous donne quelques règles élémentaires du test A/B. Le principe de ce genre de test est simple : plutôt que de tester les performances de vos interfaces avant leur sortie avec un panel limité d'utilisateurs ; préférer faire le test en production, avec plus de visiteurs, en redirigeant une partie des utilisateurs sur une proposition A et l'autre partie sur une proposition B.</p>
<p>Le test A/B permet de sonder un nombre plus important de personnes, donc d'avoir un retour plus fiable sur la performance de certaines interfaces. Ce type de test propose l'avantage d'avoir un retour de la performance dans des conditions de production, sans perturber le fonctionnement global du site, puisque seule une petite partie des visiteurs est soumise aux tests.</p>
<h3>Fixer les objectifs principaux</h3>
<p>Pour mesurer le succès d'une batterie de tests, il est important de définir au préalable les objectifs à atteindre, par exemple :</p>
<ul>
<li>Augmenter le trafic</li>
<li>Augmenter l'engagement utilisateur</li>
<li>Améliorer la rentabilité de la publicité</li>
<li>...</li>
</ul>
<p>Quel que soit le test à mettre en place, insister pour appliquer qu'un seul type de test à la fois. C'est la seule façon de mesurer et de garantir les résultats : quand je mets le bouton à droite, la conversion utilisateurs augmente de 22%.</p>
<p>Le A/B testing n'est pas facile, non seulement, il faut définir les objectifs (un seul à la fois), mais aussi ne modifier qu'un seul élément à la fois. Cette manière de procéder est la seule permettant de bien valider si une modification est bénéfique et surtout d'en déterminer la raison véritable.</p>
<h3>Oui, mais quoi tester ?</h3>
<p>Une page bourrée de liens devant vous, des choix divers pour chacun des visiteurs du site, par quoi faut-il commencer ? Plusieurs pistes pour décider de la fonctionnalité à passer au banc d'essai.</p>
<ul>
<li>Séance de tests utilisateurs pour faire un bilan du site</li>
<li>Solliciter ses meilleurs amis et ses collègues</li>
<li>Fouiller les statistiques (analytics) du site</li>
<li>User de la carte de chaleur (heatmap) pour voir où les usagers cliquent</li>
</ul>
<h3>Construire son test</h3>
<p>On a l'objectif, on a les recommandations sur les améliorations à apporter ; maintenant, il faut définir le test. Pour cela déterminer les variations possibles de l'élément à tester.</p>
<p>Attention car trop de variations augmente les temps de tests et trop peu de variations peut donner des résultats peu significatifs. Il faut trouver le juste milieu.</p>
<p>Le test dépend de chaque site. Il est possible de s'inspirer de la concurrence pour commencer. L'exercice sera un savant mélange entre pertinence et créativité.</p>
<h3>Conclusion</h3>
<p>Le test A/B est très séduisant dans la forme, il peut permettre d'avoir des certitudes sur la mise en place d'une évolution sur le site de production : ça marche moins bien ou ça marche mieux. Seulement, pour qu'un test soit significatif, il faut que le protocole soit défini de manière rigoureuse par rapport à un objectif précis. D'une certaine manière, il faut que le gain par rapport au temps passé soit positif.</p>
<p>Lire <a href="http://www.uxbooth.com/blog/gathering-variables-for-ab-split-testing/" title="Gathering variables for A/B split testing - Paras Chopra">Gathering variables for A/B split testing</a>.</p>
